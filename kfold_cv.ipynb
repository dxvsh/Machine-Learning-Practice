{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold Cross validation\n",
    "\n",
    "This notebook gives a quick demo of using KFold CV in sklearn.\n",
    "\n",
    "We'll be trying different models (Logistic Regression, SVM, RandomForest) on the digits dataset and then use k-fold cross-validation to see which model gives us the best score.\n",
    "\n",
    "Here's a quick example of what we're trying to do using k-fold cv:\n",
    "\n",
    "Suppose your dataset has a 1000 samples, you divide into 5 separate chunks (called Folds) each of which have 200 samples. Now, you can train your model on the data from 4 folds and use the 5th fold for testing the model performance. You can do this 5 different times, each time you choose a different fold for testing and use the remaining 4 folds for training the model. You'll get 5 different test scores(one for each of the test folds) after doing this. You can then take the average of these scores to get a pretty robust estimate of that actually model performs.\n",
    "\n",
    "Note: In this case, our k(the number of folds) was 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9611111111111111"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here the solver parameter specifies the algorithm to use in the optimization problem\n",
    "# and the multi_class parameter specifies how the algorithm handles multiclass classification problems\n",
    "logreg_model = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "logreg_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861111111111112"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_model = RandomForestClassifier()\n",
    "randomforest_model.fit(X_train, y_train)\n",
    "randomforest_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick toy example of how the folds actually look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3) # 3-fold cross-validation\n",
    "print(kf)\n",
    "\n",
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.92222222 0.88333333 0.95264624 0.95821727 0.89415042]\n",
      "Average score:  0.9221138966264315\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg_model, X, y, cv=5)\n",
    "print(\"Scores: \", scores)\n",
    "print(\"Average score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.96111111 0.94444444 0.98328691 0.98885794 0.93871866]\n",
      "Average score:  0.9632838130609718\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm_model, X, y, cv=5)\n",
    "print(\"Scores: \", scores)\n",
    "print(\"Average score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.92777778 0.91388889 0.95264624 0.95821727 0.92479109]\n",
      "Average score:  0.935464252553389\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(randomforest_model, X, y, cv=5)\n",
    "print(\"Scores: \", scores)\n",
    "print(\"Average score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing 5-fold cross validation on our 3 different models, we can see that SVM is the best performing model out of the bunch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
