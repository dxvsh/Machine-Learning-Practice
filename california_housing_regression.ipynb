{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on California House Prediction dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic info on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_dataset = fetch_california_housing(as_frame=True)\n",
    "print(housing_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "# the features in the dataset\n",
    "print(housing_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedHouseVal']\n"
     ]
    }
   ],
   "source": [
    "# the target variable that we need to predict\n",
    "print(housing_dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "# shape of the feature matrix and the target variable\n",
    "print(housing_dataset.data.shape)\n",
    "print(housing_dataset.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20,640 samples that we have, each with 8 features. We need to use them to predict the target variable: \"MedHousVal\", the median house value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.526\n",
       "1    3.585\n",
       "2    3.521\n",
       "3    3.413\n",
       "4    3.422\n",
       "Name: MedHouseVal, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset.target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704  \n",
       "std       10.386050      2.135952      2.003532  \n",
       "min        0.692308     32.540000   -124.350000  \n",
       "25%        2.429741     33.930000   -121.800000  \n",
       "50%        2.818116     34.260000   -118.490000  \n",
       "75%        3.282261     37.710000   -118.010000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset.data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common set up\n",
    "\n",
    "We'll use `ShuffleSplit` for cross-validation with 10 splits and 20% examples set aside as test examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset into variables and splitting into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = housing_dataset.data, housing_dataset.target\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 8), (16512,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression (using the normal equation)\n",
    "\n",
    "Let's try using the normal equation method to train a linear regression model.\n",
    "\n",
    "We will set up a pipeline with two stages:\n",
    "+ Feature scaling (standard scaling) to scale features.\n",
    "+ Linear regression on the transformed feature matrix\n",
    "\n",
    "We will use Mean absolute error (MAE) for testing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Absolute Error (MAE) on the train set is: 0.52748\n",
      "The Mean Absolute Error (MAE) on the test set is: 0.53217\n"
     ]
    }
   ],
   "source": [
    "lin_reg_pipeline = Pipeline([\n",
    "    (\"feature_scaling\", StandardScaler()),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "lin_reg_cv_results = cross_validate(\n",
    "    estimator=lin_reg_pipeline,\n",
    "    X=X_train, y=y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    return_train_score=True,\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "#lin_reg_cv_results\n",
    "\n",
    "lin_reg_train_error = -1 * lin_reg_cv_results[\"train_score\"].mean()\n",
    "lin_reg_test_error = -1 * lin_reg_cv_results[\"test_score\"].mean()\n",
    "\n",
    "print(\"The Mean Absolute Error (MAE) on the train set is: {:0.5f}\".format(lin_reg_train_error))\n",
    "print(\"The Mean Absolute Error (MAE) on the test set is: {:0.5f}\".format(lin_reg_test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors are quite high. The model may be underfit. We can address it by adding mode features through polynomial regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression using polynomial features\n",
    "\n",
    "Let's try to add a step to our pipeline that applies a degree 2 polynomial transformation to our features and see if we can improve performance a little.\n",
    "\n",
    "We set the `interaction_only` parameter to True so that only the interaction pairs (pairs of values multiplied with each other) are included. The higher order features will not be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Absolute Error (MAE) on the train set is: 0.47692\n",
      "The Mean Absolute Error (MAE) on the test set is: 0.51461\n"
     ]
    }
   ],
   "source": [
    "poly_reg_pipeline = Pipeline([\n",
    "    (\"polynomial_transform\", PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    (\"feature_scaling\", StandardScaler()),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "poly_reg_cv_results = cross_validate(\n",
    "    estimator=poly_reg_pipeline,\n",
    "    X=X_train, y=y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    return_train_score=True,\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "#poly_reg_cv_results\n",
    "\n",
    "poly_reg_train_error = -1 * poly_reg_cv_results[\"train_score\"].mean()\n",
    "poly_reg_test_error = -1 * poly_reg_cv_results[\"test_score\"].mean()\n",
    "\n",
    "print(\"The Mean Absolute Error (MAE) on the train set is: {:0.5f}\".format(poly_reg_train_error))\n",
    "print(\"The Mean Absolute Error (MAE) on the test set is: {:0.5f}\".format(poly_reg_test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both the training and test errors went down a little after applying a polynomial transformation to our features.\n",
    "\n",
    "We can also make a plot using the validation curve to see which value of the degree parameter can give the best results to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Absolute Error (MAE)')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "degree = [1, 2, 3, 4, 5]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    estimator=poly_reg_pipeline,\n",
    "    X=X_train, y=y_train,\n",
    "    param_name=\"polynomial_transform__degree\",\n",
    "    param_range=degree,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "\n",
    "train_errors, test_errors = -train_scores.mean(axis=1), -test_scores.mean(axis=1)\n",
    "\n",
    "plt.plot(degree, train_errors, \"b-x\", label=\"Train Error\")\n",
    "plt.plot(degree, test_errors, \"r-x\", label=\"Test Error\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as we increase the degree, the train error keeps going down but the test error increases dramatically using any degree greater than 2. This indicates that degree=2 is where the train and test errors are both minimized. Going past this, we'll just be overfitting on the train data and perform horribly on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression using SGD\n",
    "\n",
    "Again, we'll first be using feature scaling and then performing regression using SGDRegressor.\n",
    "\n",
    "We'll use the early stopping criteria to stop SGD if it doesn't converge under a certain number of iterations or if the error does not improve(and remains the same) for 5 consecutive iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Absolute Error (MAE) on the train set is: 0.52804\n",
      "The Mean Absolute Error (MAE) on the test set is: 0.53269\n"
     ]
    }
   ],
   "source": [
    "sgd_reg_pipeline = Pipeline([\n",
    "    (\"feature_scaling\", StandardScaler()),\n",
    "    (\"sgd_reg\", SGDRegressor(\n",
    "        random_state=42,\n",
    "        max_iter=55,\n",
    "        early_stopping=True,\n",
    "        eta0=0.0001,\n",
    "        learning_rate=\"constant\",\n",
    "        tol=1e-5,\n",
    "        validation_fraction=0.1,\n",
    "        average=10,\n",
    "        n_iter_no_change=5))])\n",
    "\n",
    "sgd_reg_cv_results = cross_validate(\n",
    "    estimator=sgd_reg_pipeline,\n",
    "    X=X_train, y=y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    return_train_score=True,\n",
    "    return_estimator=True)\n",
    "\n",
    "\n",
    "sgd_reg_train_error = -1 * sgd_reg_cv_results[\"train_score\"].mean()\n",
    "sgd_reg_test_error = -1 * sgd_reg_cv_results[\"test_score\"].mean()\n",
    "\n",
    "print(\"The Mean Absolute Error (MAE) on the train set is: {:0.5f}\".format(sgd_reg_train_error))\n",
    "print(\"The Mean Absolute Error (MAE) on the test set is: {:0.5f}\".format(sgd_reg_test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression\n",
    "\n",
    "The polynomial models have a tendency to overfit if we use higher order polynomial features. We will try using Ridge regression which penalizes excessive model complexity in the polynomial regression by adding a regularisation term. We need to specify the regularisation rate `alpha` for training the regression model. We can try using hyperparameter tuning to look for a good value of alpha that gives us the least error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=42, test_size=0.2, train_size=None),\n",
       "             estimator=Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                        PolynomialFeatures(interaction_only=True)),\n",
       "                                       (&#x27;feature_scaling&#x27;, StandardScaler()),\n",
       "                                       (&#x27;ridge_reg&#x27;, Ridge())]),\n",
       "             param_grid={&#x27;ridge_reg__alpha&#x27;: array([1.00000000e-04, 2.78255940e-04, 7.74263683e-04, 2.15443469e-03,\n",
       "       5.99484250e-03, 1.66810054e-02, 4.64158883e-02, 1.29154967e-01,\n",
       "       3.59381366e-01, 1.00000000e+00])},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=42, test_size=0.2, train_size=None),\n",
       "             estimator=Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                        PolynomialFeatures(interaction_only=True)),\n",
       "                                       (&#x27;feature_scaling&#x27;, StandardScaler()),\n",
       "                                       (&#x27;ridge_reg&#x27;, Ridge())]),\n",
       "             param_grid={&#x27;ridge_reg__alpha&#x27;: array([1.00000000e-04, 2.78255940e-04, 7.74263683e-04, 2.15443469e-03,\n",
       "       5.99484250e-03, 1.66810054e-02, 4.64158883e-02, 1.29154967e-01,\n",
       "       3.59381366e-01, 1.00000000e+00])},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures(interaction_only=True)),\n",
       "                (&#x27;feature_scaling&#x27;, StandardScaler()), (&#x27;ridge_reg&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(interaction_only=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=42, test_size=0.2, train_size=None),\n",
       "             estimator=Pipeline(steps=[('poly',\n",
       "                                        PolynomialFeatures(interaction_only=True)),\n",
       "                                       ('feature_scaling', StandardScaler()),\n",
       "                                       ('ridge_reg', Ridge())]),\n",
       "             param_grid={'ridge_reg__alpha': array([1.00000000e-04, 2.78255940e-04, 7.74263683e-04, 2.15443469e-03,\n",
       "       5.99484250e-03, 1.66810054e-02, 4.64158883e-02, 1.29154967e-01,\n",
       "       3.59381366e-01, 1.00000000e+00])},\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_list = np.logspace(-4, 0, 10)\n",
    "#print(alpha_list)\n",
    "\n",
    "ridge_reg_pipeline = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    (\"feature_scaling\", StandardScaler()),\n",
    "    (\"ridge_reg\", Ridge())])\n",
    "\n",
    "ridge_grid_search = GridSearchCV(\n",
    "    estimator=ridge_reg_pipeline,\n",
    "    param_grid={\"ridge_reg__alpha\": alpha_list},\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    return_train_score=True)\n",
    "\n",
    "ridge_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ridge_grid_search.best_params_` gives us the best parameter found in the search.\n",
    "\n",
    "`ridge_grid_search.best_index_` gives us the index of the best param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge_reg__alpha': 0.046415888336127774}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best mean absolute error (MAE) of polynomial ridge regression on the train set is: 0.47979\n",
      "The best mean absolute error (MAE) of polynomial ridge regression on the test set is: 0.51198\n"
     ]
    }
   ],
   "source": [
    "# we want the mean error produced by the best value of alpha\n",
    "mean_train_error = -1 * ridge_grid_search.cv_results_[\"mean_train_score\"][ridge_grid_search.best_index_]\n",
    "mean_test_error = -1 * ridge_grid_search.cv_results_[\"mean_test_score\"][ridge_grid_search.best_index_]\n",
    "\n",
    "print(\"The best mean absolute error (MAE) of polynomial ridge regression on the train set is: {:0.5f}\".format(mean_train_error))\n",
    "print(\"The best mean absolute error (MAE) of polynomial ridge regression on the test set is: {:0.5f}\".format(mean_test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression\n",
    "\n",
    "Trying out lasso regression which performs a more aggressive regularisation. We'll also use hyper parameter tuning to determine an optimal value of the regularisation parameter `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.814e+03, tolerance: 1.759e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+03, tolerance: 1.760e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+03, tolerance: 1.786e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e+03, tolerance: 1.751e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.485e+03, tolerance: 1.760e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+03, tolerance: 1.768e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+03, tolerance: 1.782e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+03, tolerance: 1.757e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+03, tolerance: 1.756e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e+02, tolerance: 1.751e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e+03, tolerance: 1.746e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.552e+02, tolerance: 1.759e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.109e+02, tolerance: 1.786e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.746e+02, tolerance: 1.760e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+02, tolerance: 1.768e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.961e+02, tolerance: 1.757e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e+02, tolerance: 1.760e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+02, tolerance: 1.756e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.831e+02, tolerance: 1.782e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.880e+02, tolerance: 1.746e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.450e+00, tolerance: 1.751e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.017e+00, tolerance: 1.786e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.474e+00, tolerance: 1.760e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.856e+00, tolerance: 1.759e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+00, tolerance: 1.760e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.968e+00, tolerance: 1.757e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.809e+00, tolerance: 1.768e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.988e+00, tolerance: 1.746e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.377e+00, tolerance: 1.756e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.609e+00, tolerance: 1.782e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/athena/Downloads/MLP/MLP_Code/venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.989e+00, tolerance: 2.207e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=42, test_size=0.2, train_size=None),\n",
       "             estimator=Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                        PolynomialFeatures(interaction_only=True)),\n",
       "                                       (&#x27;feature_scaling&#x27;, StandardScaler()),\n",
       "                                       (&#x27;lasso_reg&#x27;, Lasso())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;lasso_reg__alpha&#x27;: array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=42, test_size=0.2, train_size=None),\n",
       "             estimator=Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                        PolynomialFeatures(interaction_only=True)),\n",
       "                                       (&#x27;feature_scaling&#x27;, StandardScaler()),\n",
       "                                       (&#x27;lasso_reg&#x27;, Lasso())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;lasso_reg__alpha&#x27;: array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures(interaction_only=True)),\n",
       "                (&#x27;feature_scaling&#x27;, StandardScaler()), (&#x27;lasso_reg&#x27;, Lasso())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(interaction_only=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=42, test_size=0.2, train_size=None),\n",
       "             estimator=Pipeline(steps=[('poly',\n",
       "                                        PolynomialFeatures(interaction_only=True)),\n",
       "                                       ('feature_scaling', StandardScaler()),\n",
       "                                       ('lasso_reg', Lasso())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lasso_reg__alpha': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])},\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the list of alphas we want to try out\n",
    "alpha_list = np.logspace(-4, 0, 5)\n",
    "\n",
    "lasso_reg_pipeline = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    (\"feature_scaling\", StandardScaler()),\n",
    "    (\"lasso_reg\", Lasso())])\n",
    "\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    estimator=lasso_reg_pipeline,\n",
    "    param_grid={\"lasso_reg__alpha\": alpha_list},\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    return_train_score=True)\n",
    "\n",
    "lasso_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso_reg__alpha': 0.01}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best mean absolute error (MAE) of polynomial lasso regression on the train set is: 0.52501\n",
      "The best mean absolute error (MAE) of polynomial lasso regression on the test set is: 0.53003\n"
     ]
    }
   ],
   "source": [
    "mean_train_error = -1 * lasso_grid_search.cv_results_[\"mean_train_score\"][lasso_grid_search.best_index_]\n",
    "mean_test_error = -1 * lasso_grid_search.cv_results_[\"mean_test_score\"][lasso_grid_search.best_index_]\n",
    "\n",
    "print(\"The best mean absolute error (MAE) of polynomial lasso regression on the train set is: {:0.5f}\".format(mean_train_error))\n",
    "print(\"The best mean absolute error (MAE) of polynomial lasso regression on the test set is: {:0.5f}\".format(mean_test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test set\n",
    "\n",
    "Let's check the performance of different models on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression with normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27272892822514455"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, lin_reg_cv_results['estimator'][0].predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear regression with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28384837320399975"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, poly_reg_cv_results['estimator'][0].predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30945359868486205"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, sgd_reg_cv_results['estimator'][0].predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge regression using polynomial features and tuned value of alpha using HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28469061501196724"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, ridge_grid_search.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso regression using polynomial features and tuned value of alpha using HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31803185827759184"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, lasso_grid_search.best_estimator_.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
